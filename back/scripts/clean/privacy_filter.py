"""
Í∞úÏù∏Ï†ïÎ≥¥ ÌïÑÌÑ∞ÎßÅ Î™®Îìà (KLUE + GLiNER ÌïòÏù¥Î∏åÎ¶¨Îìú)
üîß ÎßàÏä§ÌÇπ Ï†ÑÏö© - ÌïòÎìúÏΩîÎî© Ï†úÍ±∞
"""

import re
from typing import Dict, List, Tuple, Optional

try:
    from presidio_analyzer import AnalyzerEngine
    from presidio_anonymizer import AnonymizerEngine

    PRESIDIO_AVAILABLE = True
except ImportError:
    PRESIDIO_AVAILABLE = False

try:
    from transformers import pipeline

    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

try:
    from gliner import GLiNER

    GLINER_AVAILABLE = True
except ImportError:
    GLINER_AVAILABLE = False


class PrivacyFilter:
    """ÎßàÏä§ÌÇπ Ï†ÑÏö© ÌïÑÌÑ∞ (ÌïòÎìúÏΩîÎî© ÏóÜÏùå, T5Í∞Ä Î™®Îì† Ï†ïÎ¶¨ Îã¥Îãπ)"""

    def __init__(
        self,
        use_ner_model: bool = True,
        ner_model_name: str = None,
        use_gliner: bool = True,
        custom_gliner_labels: List[str] = None,
    ):
        self.use_presidio = PRESIDIO_AVAILABLE
        self.use_ner = use_ner_model and TRANSFORMERS_AVAILABLE
        self.use_gliner = use_gliner and GLINER_AVAILABLE

        self.ner_pipeline = None
        self.gliner_model = None

        print("\n" + "=" * 70)
        print("üîí KLUE + GLiNER ÌïòÏù¥Î∏åÎ¶¨Îìú ÌïÑÌÑ∞ (ÎßàÏä§ÌÇπ Ï†ÑÏö©)")
        print("=" * 70)

        # 1. Presidio
        if self.use_presidio:
            print("\n‚úì Presidio AI Ï¥àÍ∏∞Ìôî Ï§ë...")
            try:
                self.analyzer = AnalyzerEngine()
                self.anonymizer = AnonymizerEngine()
                print("  ‚úì Presidio Î°úÎìú ÏôÑÎ£å")
            except Exception as e:
                print(f"  ‚ö†Ô∏è Presidio Î°úÎìú Ïã§Ìå®: {e}")
                self.use_presidio = False

        # 2. KLUE NER
        if self.use_ner:
            print("\n‚úì KLUE NER Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ï§ë...")
            model_candidates = [
                ner_model_name,
                "soddokayo/klue-roberta-large-klue-ner",
                "vitus9988/klue-roberta-large-ner-identified",
                "Leo97/KoELECTRA-small-v3-modu-ner",
            ]

            ner_loaded = False
            for model_name_try in model_candidates:
                if model_name_try is None:
                    continue

                try:
                    print(f"  ‚Üí ÏãúÎèÑ: {model_name_try}")
                    self.ner_pipeline = pipeline(
                        "ner", model=model_name_try, aggregation_strategy="simple"
                    )
                    print(f"  ‚úì KLUE Î°úÎìú ÏôÑÎ£å: {model_name_try}")

                    if "soddokayo" in model_name_try:
                        print(f"     üìä F1 0.836 | Precision 0.829 | Recall 0.844")

                    ner_loaded = True
                    break
                except Exception:
                    print(f"  ‚ö†Ô∏è Ïã§Ìå®, Îã§Ïùå ÏãúÎèÑ...")
                    continue

            if not ner_loaded:
                print("  ‚ö†Ô∏è KLUE Î™®Îç∏ Î°úÎìú Ïã§Ìå®")
                self.use_ner = False

        # 3. GLiNER
        if self.use_gliner:
            print("\n‚úì GLiNER Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ï§ë...")
            try:
                print(f"  ‚Üí ÏãúÎèÑ: taeminlee/gliner_ko")
                self.gliner_model = GLiNER.from_pretrained("taeminlee/gliner_ko")
                print(f"  ‚úì GLiNER Î°úÎìú ÏôÑÎ£å")

                self.gliner_labels = custom_gliner_labels or [
                    "ÏßÅÍ∏â",
                    "ÏßÅÌï®",
                    "Î∂ÄÏÑú",
                    "Ïó∞Î¥â",
                    "ÌèâÍ∞ÄÎì±Í∏â",
                    "ÏÇ¨Î≤à",
                    "Ï†ÑÌôîÎ≤àÌò∏",
                    "Í≥ÑÏ¢åÎ≤àÌò∏",
                ]

                print(f"     üìã GLiNER ÎùºÎ≤®: {', '.join(self.gliner_labels)}")

            except Exception as e:
                print(f"  ‚ö†Ô∏è GLiNER Î°úÎìú Ïã§Ìå®: {e}")
                self.use_gliner = False

        print("\n" + "=" * 70)
        print("üìä ÌôúÏÑ±ÌôîÎêú ÌïÑÌÑ∞:")
        print("=" * 70)
        print(f"  - Presidio: {'‚úì' if self.use_presidio else '‚úó'}")
        print(f"  - KLUE NER: {'‚úì' if self.use_ner else '‚úó'}")
        print(f"  - GLiNER: {'‚úì' if self.use_gliner else '‚úó'}")
        print(f"  - ÎßàÏä§ÌÇπ Ï†ÑÏö©: ‚úì (ÌïòÎìúÏΩîÎî© ÏóÜÏùå)")
        print("=" * 70 + "\n")

    def filter_text(
        self,
        text: str,
        confidence_threshold: float = 0.6,
        gliner_confidence: float = 0.5,
        custom_labels: Optional[List[str]] = None,
        filter_simple_numbers: bool = False,
    ) -> Dict:
        """ÌÖçÏä§Ìä∏ÏóêÏÑú Í∞úÏù∏Ï†ïÎ≥¥ ÌïÑÌÑ∞ÎßÅ (ÎßàÏä§ÌÇπ Î∞©Ïãù)"""
        if not text:
            return {
                "filtered_text": "",
                "found_items": [],
                "changes_made": False,
                "detection_methods": [],
            }

        all_detections = []
        methods_used = []

        # 1. Presidio
        if self.use_presidio:
            detections = self._detect_with_presidio(text)
            all_detections.extend(detections)
            if detections:
                methods_used.append("presidio")

        # 2. KLUE
        if self.use_ner:
            detections = self._detect_with_ner(
                text, confidence_threshold, filter_simple_numbers
            )
            all_detections.extend(detections)
            if detections:
                methods_used.append("klue_ner_model")

        # 3. GLiNER
        if self.use_gliner:
            labels = custom_labels or self.gliner_labels
            detections = self._detect_with_gliner(text, labels, gliner_confidence)
            all_detections.extend(detections)
            if detections:
                methods_used.append("gliner_zeroshot")

        merged = self._merge_detections(all_detections)

        # ÎßàÏä§ÌÇπ Ï≤òÎ¶¨ (ÌõÑÏ≤òÎ¶¨ ÏóÜÏùå, T5Í∞Ä Ï≤òÎ¶¨)
        filtered_text = self._mask_detections(text, merged)

        found_items = self._format_findings(merged)

        return {
            "filtered_text": filtered_text,
            "found_items": found_items,
            "changes_made": len(merged) > 0,
            "detection_methods": methods_used,
        }

    def _detect_with_presidio(self, text: str) -> List[Tuple]:
        """PresidioÎ°ú Ïù¥Î©îÏùº, Ï†ÑÌôîÎ≤àÌò∏ Í≤ÄÏ∂ú"""
        detections = []
        try:
            results = self.analyzer.analyze(
                text=text,
                language="en",
                entities=["EMAIL_ADDRESS", "PHONE_NUMBER"],
                return_decision_process=False,
            )
            for result in results:
                entity_text = text[result.start : result.end]
                detections.append(
                    (
                        result.start,
                        result.end,
                        entity_text,
                        result.entity_type,
                        float(result.score),
                    )
                )
        except Exception:
            pass
        return detections

    def _detect_with_ner(
        self, text: str, threshold: float, filter_simple_numbers: bool
    ) -> List[Tuple]:
        """KLUE NERÎ°ú Ïù¥Î¶Ñ, ÎÇ†Ïßú Îì± Í≤ÄÏ∂ú"""
        detections = []
        try:
            ner_results = self.ner_pipeline(text)
            for entity in ner_results:
                if entity["score"] >= threshold:
                    entity_type = self._map_ner_label(entity["entity_group"])
                    entity_text = entity["word"].replace("##", "")

                    if entity_type == "QUANTITY" and not filter_simple_numbers:
                        if (
                            entity_text.strip().isdigit()
                            and len(entity_text.strip()) <= 2
                        ):
                            continue

                    detections.append(
                        (
                            entity["start"],
                            entity["end"],
                            entity_text,
                            entity_type,
                            float(entity["score"]),
                        )
                    )
        except Exception:
            pass
        return detections

    def _detect_with_gliner(
        self, text: str, labels: List[str], threshold: float
    ) -> List[Tuple]:
        """GLiNERÎ°ú ÏßÅÍ∏â Îì± Í≤ÄÏ∂ú"""
        detections = []
        try:
            entities = self.gliner_model.predict_entities(
                text, labels, threshold=threshold
            )

            for entity in entities:
                entity_text = entity["text"]
                entity_label = entity["label"]
                entity_score = float(entity["score"])

                # ÏÇ¨Î≤à ÌïÑÌÑ∞ÎßÅ
                if entity_label == "ÏÇ¨Î≤à":
                    if entity_text.strip().isdigit() or len(entity_text.strip()) < 3:
                        continue

                # ÏßÅÍ∏â/ÏßÅÌï® ÌÜµÌï©
                if entity_label in ["ÏßÅÍ∏â", "ÏßÅÌï®"]:
                    entity_label = "ÏßÅÍ∏â"

                detections.append(
                    (
                        entity["start"],
                        entity["end"],
                        entity_text,
                        entity_label,
                        entity_score,
                    )
                )
        except Exception as e:
            print(f"    ‚ö†Ô∏è GLiNER Í≤ÄÏ∂ú Ï§ë Ïò§Î•ò: {e}")

        return detections

    def _map_ner_label(self, label: str) -> str:
        """NER ÎùºÎ≤® Îß§Ìïë"""
        label_map = {
            "PER": "PERSON",
            "PERSON": "PERSON",
            "PS": "PERSON",
            "LOC": "LOCATION",
            "LOCATION": "LOCATION",
            "LC": "LOCATION",
            "ORG": "ORGANIZATION",
            "ORGANIZATION": "ORGANIZATION",
            "OG": "ORGANIZATION",
            "DAT": "DATE",
            "DATE": "DATE",
            "DT": "DATE",
            "TIM": "TIME",
            "TIME": "TIME",
            "TI": "TIME",
            "QT": "QUANTITY",
            "QUANTITY": "QUANTITY",
        }
        return label_map.get(label.upper(), label)

    def _merge_detections(self, detections: List[Tuple]) -> List[Tuple]:
        """Ï§ëÎ≥µ Í≤ÄÏ∂ú Î≥ëÌï©"""
        if not detections:
            return []

        sorted_detections = sorted(detections, key=lambda x: (x[0], -x[1]))
        merged = []

        for detection in sorted_detections:
            start, end, text, entity_type, score = detection
            overlap = False

            for i, (m_start, m_end, m_text, m_type, m_score) in enumerate(merged):
                if start >= m_start and end <= m_end:
                    overlap = True
                    if score > m_score:
                        merged[i] = detection
                    break
                elif start < m_end and end > m_start:
                    overlap = True
                    if (end - start) > (m_end - m_start):
                        merged[i] = detection
                    break

            if not overlap:
                merged.append(detection)

        return merged

    def _mask_detections(self, text: str, detections: List[Tuple]) -> str:
        """Í≤ÄÏ∂úÎêú Í∞úÏù∏Ï†ïÎ≥¥Î•º ÎßàÏä§ÌÅ¨Î°ú ÎåÄÏ≤¥ (ÌõÑÏ≤òÎ¶¨ ÏóÜÏùå)"""
        sorted_detections = sorted(detections, key=lambda x: x[0], reverse=True)
        for start, end, _, entity_type, _ in sorted_detections:
            mask = f"[{entity_type}]"
            text = text[:start] + mask + text[end:]
        return text

    def _format_findings(self, detections: List[Tuple]) -> List[Dict]:
        """Í≤ÄÏ∂ú Í≤∞Í≥º Ìè¨Îß∑ÌåÖ"""
        findings_by_type = {}

        for _, _, text, entity_type, score in detections:
            if entity_type not in findings_by_type:
                findings_by_type[entity_type] = {"items": [], "scores": []}
            findings_by_type[entity_type]["items"].append(text)
            findings_by_type[entity_type]["scores"].append(score)

        result = []
        for entity_type, data in findings_by_type.items():
            avg_score = sum(data["scores"]) / len(data["scores"])
            result.append(
                {
                    "type": entity_type,
                    "count": len(data["items"]),
                    "examples": data["items"][:5],
                    "avg_confidence": round(avg_score, 3),
                    "method": "hybrid",
                }
            )
        return result
